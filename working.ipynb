{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1_deck\n",
      "draw\n",
      "p1 score\n",
      "p2_deck\n",
      "p2 score\n",
      "p1 will\n",
      "p2 will\n",
      "influence\n",
      "winner\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import logging\n",
    "import classes #import the module here, so that it can be reloaded.\n",
    "importlib.reload(classes)\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.DEBUG)    \n",
    "\n",
    "game = classes.Game()\n",
    "players = [classes.Player(\"P1\"),classes.Player(\"P2\")]\n",
    "game.start_game(players)\n",
    "game_result,turn_results = game.run_game(players)\n",
    "for k in  game_result:\n",
    "    print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "game = classes.Game()\n",
    "players = [classes.Player(\"P1\"),classes.Player(\"P2\")]\n",
    "game.start_game(players)\n",
    "cProfile.run('result = game.run_game(players)')\n",
    "del game\n",
    "del players   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import pandas as pd\n",
    "game_cols = ['p1_deck','p1 score','p2_deck','p2 score','p1 will','p2 will','influence','winner','draw']\n",
    "game_data = {}\n",
    "for c in game_cols: game_data[c] = []\n",
    "\n",
    "def capture_data():\n",
    "    for i in range(10000):\n",
    "        game = classes.Game()\n",
    "        players = [classes.Player(\"P1\"),classes.Player(\"P2\")]\n",
    "        game.start_game(players)\n",
    "        game_result,turn_results = game.run_game(players)\n",
    "        for c in game_cols: game_data[c].append(game_result[c]) \n",
    "        del game\n",
    "        del players   \n",
    "capture_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.056\n",
      "13879032\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(game_data)\n",
    "print(sum(data[\"draw\"])/len(data))\n",
    "print( sys.getsizeof(data))\n",
    "print(len(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "for i in range(2):\n",
    "    player = \"p\"+str(i+1)\n",
    "    #these columns are dictionary that contain the number of cards in the deck, the numnbr of seasons, the cumulative power of each season\n",
    "    data[player+\"_deck_cards\"] = data[player+\"_deck\"].apply(lambda x: Counter(x))\n",
    "    data[player+\"_deck_season\"] = data[player+\"_deck\"].apply(lambda c: Counter(x[0] for x in c))\n",
    "    data[player+\"_deck_power\"] = data[player+\"_deck\"].apply(lambda c:  Counter(\"\".join(x[0]*int(x[1]) for x in c )))\n",
    "    for s in season_short:\n",
    "        data[player+\"_deck_season_\"+s] = data[player+\"_deck_season\"].apply(lambda x: x.get(s,0))\n",
    "        data[player+\"_deck_power_\"+s] = data[player+\"_deck_power\"].apply(lambda x: x.get(s,0))\n",
    "        for p in range(3):\n",
    "            data[player+\"_deck_\"+s+str(p+1)] = data[player+\"_deck_cards\"].apply(lambda x: x.get(s+str(p+1),0))\n",
    "    data = data.drop([player+\"_deck_season\"], axis=1)\n",
    "    data = data.drop([player+\"_deck_power\"], axis=1)\n",
    "    data = data.drop([player+\"_deck_cards\"], axis=1)\n",
    "for s in season_short:\n",
    "    data[\"diff_deck_season_\"+s] = data[\"p1_deck_season_\"+s] - data[\"p2_deck_season_\"+s]\n",
    "    data[\"diff_deck_power_\"+s] = data[\"p1_deck_power_\"+s] - data[\"p2_deck_power_\"+s]\n",
    "    for p in range(3):\n",
    "        data[\"diff_deck_\"+s+str(p+1)] = data[\"p1_deck_\"+s+str(p+1)] - data[\"p2_deck_\"+s+str(p+1)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18839032\n",
      "71\n",
      "    draw                          influence  p1 score  \\\n",
      "0  False  {'r': 6, 'q': 6, 'e': 11, 'w': 8}        17   \n",
      "1  False  {'r': 7, 'q': 16, 'e': 5, 'w': 7}        28   \n",
      "2  False  {'r': 7, 'q': 6, 'e': 6, 'w': 12}         6   \n",
      "\n",
      "                            p1 will  \\\n",
      "0  {'r': 3, 'q': 6, 'e': 2, 'w': 5}   \n",
      "1  {'r': 6, 'q': 0, 'e': 7, 'w': 3}   \n",
      "2  {'r': 3, 'q': 6, 'e': 3, 'w': 4}   \n",
      "\n",
      "                                             p1_deck  p2 score  \\\n",
      "0  [e1, r1, w2, e2, e2, r3, r1, q1, e2, q2, r2, w...        31   \n",
      "1  [w1, r1, q2, w2, w2, w3, e1, q1, e2, q2, r2, r...        38   \n",
      "2  [q1, r1, q2, w2, r2, w3, w1, e1, q2, e2, e2, q...        22   \n",
      "\n",
      "                            p2 will  \\\n",
      "0  {'r': 6, 'q': 3, 'e': 5, 'w': 5}   \n",
      "1  {'r': 4, 'q': 2, 'e': 3, 'w': 6}   \n",
      "2  {'r': 5, 'q': 6, 'e': 4, 'w': 4}   \n",
      "\n",
      "                                             p2_deck winner  p1_deck_season_q  \\\n",
      "0  [e1, e1, w2, r2, q2, e3, r1, r1, w2, q2, q2, q...     P2                 4   \n",
      "1  [q1, w1, w2, e2, r2, q3, r1, e1, e2, e2, e2, r...     P2                 5   \n",
      "2  [r1, e1, q2, e2, q2, w3, w1, w1, r2, r2, w2, e...     P2                 5   \n",
      "\n",
      "   ...  diff_deck_e1  diff_deck_e2  diff_deck_e3  diff_deck_season_r  \\\n",
      "0  ...             0             2             0                   3   \n",
      "1  ...             0            -3             1                  -1   \n",
      "2  ...             0             2            -1                  -2   \n",
      "\n",
      "   diff_deck_power_r  diff_deck_r1  diff_deck_r2  diff_deck_r3  \\\n",
      "0                  7             0             2             1   \n",
      "1                 -1            -1             0             0   \n",
      "2                 -3             0            -3             1   \n",
      "\n",
      "   diff_deck_season_var  diff_deck_power_var  \n",
      "0                  2.75               7.6875  \n",
      "1                  1.25               3.1875  \n",
      "2                  1.25               3.6875  \n",
      "\n",
      "[3 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "def var_4(a,b,c,d):\n",
    "    in_list = [a,b,c,d]\n",
    "    mean = sum(in_list)/4\n",
    "    return(sum( (x-mean)**2 for x in in_list )/4)\n",
    "    \n",
    "data[\"diff_deck_season_var\"] = var_4(data[\"p1_deck_season_q\"],data[\"p1_deck_season_w\"],data[\"p1_deck_season_e\"],data[\"p1_deck_season_r\"] )\n",
    "data[\"diff_deck_power_var\"] = var_4(data[\"p1_deck_power_q\"],data[\"p1_deck_power_w\"],data[\"p1_deck_power_e\"],data[\"p1_deck_power_r\"] )\n",
    "print( sys.getsizeof(data))\n",
    "print(len(data.columns))\n",
    "print(data[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['draw', 'influence', 'p1 score', 'p1 will', 'p1_deck', 'p2 score',\n",
      "       'p2 will', 'p2_deck', 'winner', 'p1_deck_season_q', 'p1_deck_power_q',\n",
      "       'p1_deck_q1', 'p1_deck_q2', 'p1_deck_q3', 'p1_deck_season_w',\n",
      "       'p1_deck_power_w', 'p1_deck_w1', 'p1_deck_w2', 'p1_deck_w3',\n",
      "       'p1_deck_season_e', 'p1_deck_power_e', 'p1_deck_e1', 'p1_deck_e2',\n",
      "       'p1_deck_e3', 'p1_deck_season_r', 'p1_deck_power_r', 'p1_deck_r1',\n",
      "       'p1_deck_r2', 'p1_deck_r3', 'p2_deck_season_q', 'p2_deck_power_q',\n",
      "       'p2_deck_q1', 'p2_deck_q2', 'p2_deck_q3', 'p2_deck_season_w',\n",
      "       'p2_deck_power_w', 'p2_deck_w1', 'p2_deck_w2', 'p2_deck_w3',\n",
      "       'p2_deck_season_e', 'p2_deck_power_e', 'p2_deck_e1', 'p2_deck_e2',\n",
      "       'p2_deck_e3', 'p2_deck_season_r', 'p2_deck_power_r', 'p2_deck_r1',\n",
      "       'p2_deck_r2', 'p2_deck_r3', 'diff_deck_season_q', 'diff_deck_power_q',\n",
      "       'diff_deck_q1', 'diff_deck_q2', 'diff_deck_q3', 'diff_deck_season_w',\n",
      "       'diff_deck_power_w', 'diff_deck_w1', 'diff_deck_w2', 'diff_deck_w3',\n",
      "       'diff_deck_season_e', 'diff_deck_power_e', 'diff_deck_e1',\n",
      "       'diff_deck_e2', 'diff_deck_e3', 'diff_deck_season_r',\n",
      "       'diff_deck_power_r', 'diff_deck_r1', 'diff_deck_r2', 'diff_deck_r3'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['diff_deck_season_q', 'diff_deck_power_q', 'diff_deck_q1',\n",
      "       'diff_deck_q2', 'diff_deck_q3', 'diff_deck_season_w',\n",
      "       'diff_deck_power_w', 'diff_deck_w1', 'diff_deck_w2', 'diff_deck_w3',\n",
      "       'diff_deck_season_e', 'diff_deck_power_e', 'diff_deck_e1',\n",
      "       'diff_deck_e2', 'diff_deck_e3', 'diff_deck_season_r',\n",
      "       'diff_deck_power_r', 'diff_deck_r1', 'diff_deck_r2', 'diff_deck_r3',\n",
      "       'diff_deck_season_var', 'diff_deck_power_var'],\n",
      "      dtype='object')\n",
      "   diff_deck_season_q  diff_deck_power_q  diff_deck_q1  diff_deck_q2  \\\n",
      "0                   0                 -3             2            -1   \n",
      "\n",
      "   diff_deck_q3  diff_deck_season_w  diff_deck_power_w  diff_deck_w1  \\\n",
      "0            -1                  -5                 -8            -2   \n",
      "\n",
      "   diff_deck_w2  diff_deck_w3  ...  diff_deck_e1  diff_deck_e2  diff_deck_e3  \\\n",
      "0            -3             0  ...             0             2             0   \n",
      "\n",
      "   diff_deck_season_r  diff_deck_power_r  diff_deck_r1  diff_deck_r2  \\\n",
      "0                   3                  7             0             2   \n",
      "\n",
      "   diff_deck_r3  diff_deck_season_var  diff_deck_power_var  \n",
      "0             1                  2.75               7.6875  \n",
      "\n",
      "[1 rows x 22 columns] False\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "X = data[data['draw']==False].drop(['draw','influence'] + [col for col in data.columns if col.startswith('p1')] + [col for col in data.columns if col.startswith('p2')], axis=1)\n",
    "y = X[\"winner\"] == \"P1\"\n",
    "X = X.drop(['winner'], axis=1)\n",
    "print(X.columns)\n",
    "print(X[0:1],y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth 5, min split 100, test_acc 0.528884, train_acc 0.555116 , test_mcc 0.057968 train_mcc 0.114566\n",
      "Depth 5, min split 300, test_acc 0.527331, train_acc 0.551546 , test_mcc 0.054180 train_mcc 0.106090\n",
      "Depth 5, min split 500, test_acc 0.527895, train_acc 0.550439 , test_mcc 0.055693 train_mcc 0.104104\n",
      "Depth 5, min split 700, test_acc 0.527825, train_acc 0.549894 , test_mcc 0.055730 train_mcc 0.102820\n",
      "Depth 15, min split 100, test_acc 0.521610, train_acc 0.633200 , test_mcc 0.044140 train_mcc 0.267561\n",
      "Depth 15, min split 300, test_acc 0.523694, train_acc 0.592181 , test_mcc 0.048667 train_mcc 0.185469\n",
      "Depth 15, min split 500, test_acc 0.524576, train_acc 0.579394 , test_mcc 0.049598 train_mcc 0.159590\n",
      "Depth 15, min split 700, test_acc 0.527260, train_acc 0.572446 , test_mcc 0.055360 train_mcc 0.145820\n",
      "Depth 25, min split 100, test_acc 0.519986, train_acc 0.654677 , test_mcc 0.040044 train_mcc 0.309509\n",
      "Depth 25, min split 300, test_acc 0.521363, train_acc 0.597870 , test_mcc 0.042978 train_mcc 0.195870\n",
      "Depth 25, min split 500, test_acc 0.523588, train_acc 0.582117 , test_mcc 0.047107 train_mcc 0.164567\n",
      "Depth 25, min split 700, test_acc 0.527754, train_acc 0.573748 , test_mcc 0.055741 train_mcc 0.147517\n",
      "Depth 35, min split 100, test_acc 0.520198, train_acc 0.656081 , test_mcc 0.040430 train_mcc 0.312290\n",
      "Depth 35, min split 300, test_acc 0.521610, train_acc 0.598066 , test_mcc 0.043462 train_mcc 0.196241\n",
      "Depth 35, min split 500, test_acc 0.523588, train_acc 0.582117 , test_mcc 0.047107 train_mcc 0.164567\n",
      "Depth 35, min split 700, test_acc 0.527754, train_acc 0.573748 , test_mcc 0.055741 train_mcc 0.147517\n",
      "Depth 45, min split 100, test_acc 0.520233, train_acc 0.656113 , test_mcc 0.040497 train_mcc 0.312334\n",
      "Depth 45, min split 300, test_acc 0.521610, train_acc 0.598066 , test_mcc 0.043462 train_mcc 0.196241\n",
      "Depth 45, min split 500, test_acc 0.523588, train_acc 0.582117 , test_mcc 0.047107 train_mcc 0.164567\n",
      "Depth 45, min split 700, test_acc 0.527754, train_acc 0.573748 , test_mcc 0.055741 train_mcc 0.147517\n",
      "Depth 55, min split 100, test_acc 0.520233, train_acc 0.656113 , test_mcc 0.040497 train_mcc 0.312334\n",
      "Depth 55, min split 300, test_acc 0.521610, train_acc 0.598066 , test_mcc 0.043462 train_mcc 0.196241\n",
      "Depth 55, min split 500, test_acc 0.523588, train_acc 0.582117 , test_mcc 0.047107 train_mcc 0.164567\n",
      "Depth 55, min split 700, test_acc 0.527754, train_acc 0.573748 , test_mcc 0.055741 train_mcc 0.147517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "# import the regressor \n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics \n",
    "\n",
    "for j in range(5,56,10)    :\n",
    "    for i in range(100,701,200)    :        \n",
    "        #decision tree\n",
    "        kfold = RepeatedKFold(n_splits=10, n_repeats=3,  random_state=7)\n",
    "        test_accuracy = []\n",
    "        train_accuracy = []\n",
    "        test_mcc = []\n",
    "        train_mcc = []\n",
    "        for train, test in kfold.split(X, y):\n",
    "\n",
    "            # Create Decision Tree classifer object\n",
    "            classifier = DecisionTreeClassifier(random_state = 0,max_depth = j,min_samples_split=i) \n",
    "\n",
    "            # Train Decision Tree Classifer\n",
    "            classifier = classifier.fit(X.iloc[train],y.iloc[train])\n",
    "\n",
    "            #Predict the response for test dataset\n",
    "            y_test_pred = classifier.predict(X.iloc[test])\n",
    "            y_train_pred = classifier.predict(X.iloc[train])\n",
    "            # Model Accuracy, how often is the classifier correct?\n",
    "            test_accuracy.append(metrics.accuracy_score(y.iloc[test], y_test_pred))\n",
    "            train_accuracy.append(metrics.accuracy_score(y.iloc[train],y_train_pred ))\n",
    "            test_mcc.append(metrics.matthews_corrcoef(y.iloc[test], y_test_pred))\n",
    "            train_mcc.append(metrics.matthews_corrcoef(y.iloc[train],y_train_pred ))\n",
    "            \n",
    "            importances = classifier.feature_importances_\n",
    "            indices = np.argsort(importances)[::-1]\n",
    "        \n",
    "        print(\"Depth %d, min split %d, test_acc %f, train_acc %f , test_mcc %f train_mcc %f\" % (j , i , np.mean(test_accuracy), np.mean(train_accuracy) , np.mean(test_mcc), np.mean(train_mcc)))\n",
    "    #for f in range(X.shape[1]):\n",
    "    #    print(\"%d. feature %s (%f)\" % (f + 1, X.columns[indices[f]], importances[indices[f]]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth 55, min split 700, test_acc 0.535664, train_acc 0.597277 , test_mcc 0.073423 train_mcc 0.195279\n",
      "1. feature diff_deck_power_var (0.250483)\n",
      "2. feature diff_deck_power_r (0.128218)\n",
      "3. feature diff_deck_power_q (0.111015)\n",
      "4. feature diff_deck_power_e (0.085498)\n",
      "5. feature diff_deck_power_w (0.072072)\n",
      "6. feature diff_deck_r2 (0.047968)\n",
      "7. feature diff_deck_w2 (0.043772)\n",
      "8. feature diff_deck_season_e (0.035146)\n",
      "9. feature diff_deck_e1 (0.034795)\n",
      "10. feature diff_deck_w1 (0.030844)\n",
      "11. feature diff_deck_season_w (0.028744)\n",
      "12. feature diff_deck_q2 (0.028358)\n",
      "13. feature diff_deck_season_r (0.027638)\n",
      "14. feature diff_deck_r3 (0.024428)\n",
      "15. feature diff_deck_r1 (0.021325)\n",
      "16. feature diff_deck_season_var (0.016133)\n",
      "17. feature diff_deck_w3 (0.013562)\n",
      "18. feature diff_deck_e2 (0.000000)\n",
      "19. feature diff_deck_e3 (0.000000)\n",
      "20. feature diff_deck_q3 (0.000000)\n",
      "21. feature diff_deck_q1 (0.000000)\n",
      "22. feature diff_deck_season_q (0.000000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "test_accuracy = []\n",
    "train_accuracy = []\n",
    "test_mcc = []\n",
    "train_mcc = []\n",
    "for train, test in RepeatedKFold(n_splits=10, n_repeats=3,  random_state=7).split(X, y):\n",
    "\n",
    "    # Build a forest and compute the impurity-based feature importances\n",
    "    forest = RandomForestClassifier(n_estimators=1000,max_depth=5,random_state=100)\n",
    "\n",
    "    forest.fit(X.iloc[train], y.iloc[train])\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    y_test_pred = forest.predict(X.iloc[test])\n",
    "    y_train_pred = forest.predict(X.iloc[train])\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    test_accuracy.append(metrics.accuracy_score(y.iloc[test], y_test_pred))\n",
    "    train_accuracy.append(metrics.accuracy_score(y.iloc[train],y_train_pred ))\n",
    "    test_mcc.append(metrics.matthews_corrcoef(y.iloc[test], y_test_pred))\n",
    "    train_mcc.append(metrics.matthews_corrcoef(y.iloc[train],y_train_pred ))\n",
    "    \n",
    "    importances = classifier.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "print(\"Depth %d, min split %d, test_acc %f, train_acc %f , test_mcc %f train_mcc %f\" % (j , i , np.mean(test_accuracy), np.mean(train_accuracy) , np.mean(test_mcc), np.mean(train_mcc)))\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, X.columns[indices[f]], importances[indices[f]]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-91-1344ac162fb0>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-91-1344ac162fb0>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    for each pair in hand\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#simple minimax function pseudocode\n",
    "\n",
    "def choose():\n",
    "\tchoose = empty_pair\n",
    "\tmax_points = -99\n",
    "\tfor each pair in hand\t\t\t\t\n",
    "\t\teval = min(evaluate(~pair),evaluate(pair))\n",
    "\t\tif eval  > max_points:\n",
    "\t\t\tchoose = pair\n",
    "\t\t\tmax_points = eval \n",
    "\treturn(choose)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
